{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller, NaiveCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from greedy_decoder import GreedyCTCDecoder\n",
    "from Levenshtein import ratio\n",
    "from utils import load_model, get_metrics_for_evaluation, sort_transcript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from beam_search_decoder import beam_search_ctc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 19\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\empirical\\3_3_25.pth\"\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels = labels)\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ONT_Barcode', 'HW_Address', 'Payload', 'Library_Motifs', 'read_id',\n",
      "       'squiggle', 'Motifs', 'motif_seq', 'Payload_Sequence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "model = load_model(model_path=model_path, device=device, n_classes=n_classes)\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\pickled_datasets\\28_2_25.pkl\"\n",
    "\n",
    "X, y, payloads = load_training_data(\n",
    "        dataset_path, column_x='squiggle', column_y='motif_seq', payload=True, sampling_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, payloads_train, payloads_test = train_test_split(\n",
    "        X, payloads, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea12de3ae5f4a788e2933aef19a85c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.748037338256836\n",
      "[[4], [], [1], [1], [], [], [], [1]]\n",
      "11 4 11 12 12 13 1 13 14 1 14 15 15 17 18 1 18\n",
      "[[], [], [6], [1], [8], [1], [8], [6]]\n",
      "[[3, 4, 7, 8], [1, 2, 3, 5], [3, 4, 6, 8], [1, 3, 4, 5], [1, 3, 4, 8], [1, 3, 4, 7], [2, 3, 4, 8], [1, 4, 6, 8]]\n",
      "(0.16666666666666666, 0.75, 0.16666666666666666, 0.3333333333333333)\n",
      "\n",
      "1.3448082208633423\n",
      "[[4], [], [], [1], [1, 2], [], [], []]\n",
      "11 4 11 13 13 14 1 14 15 1 15 2 18\n",
      "[[8], [6], [7], [2], [8], [5], [5], [2]]\n",
      "[[1, 3, 4, 8], [2, 4, 6, 8], [2, 3, 5, 7], [1, 2, 6, 7], [3, 6, 7, 8], [1, 2, 5, 7], [4, 5, 6, 7], [2, 4, 5, 6]]\n",
      "(0.0, 1.0, 0.0, 0.5)\n",
      "\n",
      "1.774727702140808\n",
      "[[1], [], [], [5], [1], [], [], []]\n",
      "11 1 11 13 13 14 5 14 15 1 15 18\n",
      "[[1], [], [], [4], [7], [8], [2], []]\n",
      "[[1, 3, 4, 6], [1, 4, 7, 8], [1, 3, 4, 8], [1, 2, 4, 7], [3, 5, 7, 8], [3, 6, 7, 8], [2, 5, 7, 8], [1, 3, 4, 7]]\n",
      "(0.2, 0.6666666666666666, 0.2, 0.4)\n",
      "\n",
      "1.2886781692504883\n",
      "[[4], [], [1], [1], [], [], [], [5]]\n",
      "11 4 11 12 12 13 1 13 14 1 14 15 15 17 18 5 18\n",
      "[[3], [], [5], [5], [], [6], [2], [3]]\n",
      "[[1, 3, 4, 7], [1, 6, 7, 8], [2, 5, 7, 8], [3, 4, 5, 8], [2, 3, 4, 5], [1, 3, 5, 6], [2, 4, 7, 8], [2, 3, 6, 8]]\n",
      "(0.0, 1.0, 0.0, 0.6666666666666666)\n",
      "\n",
      "2.023249864578247\n",
      "[[4], [], [], [5], [1, 2], [], [], []]\n",
      "11 4 11 13 13 14 5 14 15 1 15 2 18\n",
      "[[], [4], [8], [1, 7], [2], [1], [], []]\n",
      "[[2, 6, 7, 8], [1, 3, 4, 7], [1, 3, 6, 8], [1, 5, 7, 8], [2, 3, 4, 6], [1, 2, 5, 8], [2, 3, 4, 6], [3, 4, 5, 6]]\n",
      "(0.16666666666666666, 0.75, 0.2, 0.3)\n",
      "\n",
      "1.259348750114441\n",
      "[[4], [], [], [1], [], [], [], [1]]\n",
      "11 4 11 12 12 13 13 14 1 14 15 15 17 18 1 18\n",
      "[[5], [3], [5], [1], [1], [2], [1], [6]]\n",
      "[[2, 3, 5, 8], [3, 5, 6, 8], [3, 4, 5, 6], [1, 2, 5, 7], [1, 5, 7, 8], [2, 3, 4, 8], [1, 3, 5, 6], [1, 5, 6, 7]]\n",
      "(0.125, 0.6666666666666666, 0.125, 0.25)\n",
      "\n",
      "1.208294153213501\n",
      "[[4], [], [1], [1], [], [], [], [1]]\n",
      "11 4 11 12 12 13 1 13 14 1 14 15 15 17 18 1 18\n",
      "[[1], [7], [4], [7], [], [4], [3], [1]]\n",
      "[[1, 3, 4, 6], [1, 2, 3, 7], [1, 2, 4, 7], [2, 3, 7, 8], [1, 3, 5, 6], [1, 4, 6, 8], [1, 2, 3, 6], [1, 2, 3, 8]]\n",
      "(0.14285714285714285, 0.75, 0.14285714285714285, 0.42857142857142855)\n",
      "\n",
      "1.7596036195755005\n",
      "[[1], [], [], [5], [1], [], [], []]\n",
      "11 1 11 13 14 5 14 15 1 15 18\n",
      "[[], [8, 1], [5], [7], [], [7], [8], []]\n",
      "[[1, 3, 5, 6], [1, 3, 6, 8], [1, 5, 6, 7], [1, 2, 7, 8], [1, 4, 6, 7], [3, 4, 7, 8], [1, 2, 6, 8], [1, 3, 4, 6]]\n",
      "(0.0, 1.0, 0.0, 0.2)\n",
      "\n",
      "1.6406995058059692\n",
      "[[4], [], [], [5], [1, 2], [], [], []]\n",
      "11 4 11 13 13 14 5 14 15 1 15 2 18\n",
      "[[7], [8], [1], [7], [3], [], [], []]\n",
      "[[3, 6, 7, 8], [1, 4, 5, 8], [1, 4, 5, 7], [2, 4, 6, 7], [1, 2, 3, 5], [2, 4, 5, 8], [1, 3, 6, 8], [1, 6, 7, 8]]\n",
      "(0.0, 1.0, 0.0, 0.8)\n",
      "\n",
      "1.4830626249313354\n",
      "[[4], [], [], [1], [], [], [], [1]]\n",
      "11 4 11 12 12 13 13 14 1 14 15 15 17 18 1 18\n",
      "[[5], [8], [], [6], [5], [6], [1], []]\n",
      "[[1, 3, 5, 7], [1, 2, 3, 8], [3, 4, 6, 7], [2, 4, 5, 6], [1, 4, 5, 7], [1, 4, 6, 7], [1, 4, 5, 8], [1, 2, 3, 6]]\n",
      "(0.0, 1.0, 0.0, 0.3333333333333333)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "sum_diff = 0\n",
    "\n",
    "for x, y, payload in tqdm(zip(X_test, y_test, payloads_test), total=len(X_test)):\n",
    "    \n",
    "    input_sequence = torch.tensor(\n",
    "        x, dtype=torch.float32)\n",
    "    input_sequence = input_sequence.view(\n",
    "        1, 1, len(x)).to(device)\n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)\n",
    "    \n",
    "    label_lengths = torch.tensor([len(y)])\n",
    "    target_sequence = torch.tensor(y).to(device)\n",
    "\n",
    "    \n",
    "    n_timesteps = model_output.shape[0]\n",
    "    input_lengths = torch.tensor([n_timesteps])\n",
    "    \n",
    "    model_output_flattened = model_output.view(\n",
    "        model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "\n",
    "    loss = ctc(\n",
    "        model_output, target_sequence, input_lengths, label_lengths)\n",
    "    print(loss.item())\n",
    "    \n",
    "    greedy_transcript = \" \".join(greedy_decoder(model_output))\n",
    "    beam_transcript = beam_search_ctc(\n",
    "        model_output_flattened.detach().cpu(), beam_width=10)\n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "\n",
    "    print(sort_transcript(beam_transcript))\n",
    "    print(beam_transcript)\n",
    "    print(sort_transcript(actual_transcript))\n",
    "    print(sort_transcript(\" \".join([str(i) for i in payload])))\n",
    "    \n",
    "    greedy_ratio = ratio(greedy_transcript, actual_transcript)\n",
    "    beam_ratio = ratio(beam_transcript, actual_transcript)\n",
    "    \n",
    "    print(get_metrics_for_evaluation(greedy_transcript, actual_transcript, payload))\n",
    "    sum_diff += beam_ratio - greedy_ratio\n",
    "    print()\n",
    "\n",
    "    counter += 1\n",
    "    if counter == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
