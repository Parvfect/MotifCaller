{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller, NaiveCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from greedy_decoder import GreedyCTCDecoder\n",
    "from Levenshtein import ratio\n",
    "from utils import load_model, get_metrics_for_evaluation\n",
    "from transcript_sorting import sort_transcript_reduced_spacers, sort_transcript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from beam_search_decoder import beam_search_ctc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation_df = pd.read_csv(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\motif_search_barcoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 19\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\empirical\\model (6).pth\"\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels = labels)\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "model = load_model(model_path=model_path, device=device, n_classes=n_classes, hidden_size=512)\n",
    "\n",
    "test_dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\datasets\\empirical\\full_empirical_test_dataset_v5_payload_seq.pkl\"\n",
    "#dataset = pd.read_pickle(dataset_path)\n",
    "dataset = pd.read_pickle(test_dataset_path)\n",
    "\n",
    "#X, y, payloads = load_training_data(\n",
    "#        test_dataset_path, column_x='squiggle', column_y='motif_seq', payload=True, sampling_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientation_df = orientation_df[['read_id', 'orientation']]\n",
    "merged_df = pd.merge(dataset, orientation_df, on='read_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = merged_df.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction, original):\n",
    "\n",
    "    found = 0\n",
    "    err = 0\n",
    "    for i, j in zip(prediction, original):\n",
    "        for k in range(len(i)):\n",
    "            if i[k] in j:\n",
    "                found += 1\n",
    "            else:\n",
    "                err += 1\n",
    "\n",
    "    return found, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.335997581481934\n",
      "+|+|+|+|+\n",
      "[[5], [], [5], [3], [], [6], [1], [3]]\n",
      "[[5], [], [5], [3], [], [6], [1, 1], [3]]\n",
      "[[], [], [], [3], [6], [6], [], [3]]\n",
      "[[1, 4, 5, 8], [4, 6, 7, 8], [1, 2, 3, 4], [1, 3, 5, 6], [5, 6, 7, 8], [2, 3, 4, 6], [1, 4, 5, 6], [1, 2, 3, 4]]\n",
      "(5, 1)\n",
      "(4, 0)\n",
      "1\n",
      "\n",
      "6.338716983795166\n",
      "+|+|+|+|+|+\n",
      "[[1], [], [5], [1], [], [7], [5], [3]]\n",
      "[[1], [], [5], [1], [], [7], [5], [3]]\n",
      "[[], [1], [8], [1], [3], [], [8], []]\n",
      "[[2, 6, 7, 8], [1, 2, 3, 4], [1, 4, 7, 8], [1, 2, 5, 8], [1, 3, 4, 8], [1, 4, 5, 7], [1, 3, 5, 8], [1, 3, 7, 8]]\n",
      "(4, 2)\n",
      "(5, 0)\n",
      "0\n",
      "\n",
      "16.298765182495117\n",
      "+|+\n",
      "[[8], [], [1], [8], [], [8], [3], [5]]\n",
      "[[8], [], [1], [8], [], [8], [3], [5]]\n",
      "[[3], [], [], [6], [], [], [], []]\n",
      "[[3, 4, 5, 6], [2, 5, 6, 7], [1, 2, 4, 8], [2, 4, 6, 7], [2, 5, 7, 8], [2, 4, 7, 8], [2, 3, 4, 8], [2, 5, 6, 7]]\n",
      "(4, 2)\n",
      "(2, 0)\n",
      "2\n",
      "\n",
      "55.10380172729492\n",
      "+\n",
      "[[8], [6], [6], [6], [3], [], [3], [2]]\n",
      "[[8], [6, 6], [6, 6], [6], [3], [], [3], [2]]\n",
      "[[8], [], [], [], [], [], [], []]\n",
      "[[2, 3, 7, 8], [1, 5, 7, 8], [1, 2, 4, 5], [1, 4, 5, 8], [3, 5, 6, 8], [1, 3, 4, 8], [2, 4, 5, 8], [1, 2, 5, 6]]\n",
      "(3, 4)\n",
      "(1, 0)\n",
      "4\n",
      "\n",
      "24.1817569732666\n",
      "+|+\n",
      "[[5], [5], [5], [7], [], [5], [3], [8]]\n",
      "[[5], [5], [5], [7], [], [5], [3], [8]]\n",
      "[[], [], [8], [], [], [], [], []]\n",
      "[[3, 4, 5, 6], [2, 5, 6, 7], [1, 2, 4, 8], [2, 4, 6, 7], [2, 5, 7, 8], [2, 4, 7, 8], [2, 3, 4, 8], [2, 5, 6, 7]]\n",
      "(4, 3)\n",
      "(1, 0)\n",
      "7\n",
      "\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "sum_diff = 0\n",
    "\n",
    "for ind, row in sampled_df.iterrows():\n",
    "    \n",
    "    x = row['squiggle']\n",
    "    y = row['Spacer_Sequence']\n",
    "    payload = row['Payload_Sequence']\n",
    "    orientation = row['orientation']\n",
    "\n",
    "    if orientation.startswith('-'):\n",
    "        continue\n",
    "\n",
    "    input_sequence = torch.tensor(\n",
    "        x, dtype=torch.float32)\n",
    "    input_sequence = input_sequence.view(\n",
    "        1, 1, len(x)).to(device)\n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)\n",
    "    \n",
    "    label_lengths = torch.tensor([len(y)])\n",
    "    target_sequence = torch.tensor(y).to(device)\n",
    "\n",
    "    \n",
    "    n_timesteps = model_output.shape[0]\n",
    "    input_lengths = torch.tensor([n_timesteps])\n",
    "    \n",
    "    model_output_flattened = model_output.view(\n",
    "        model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "\n",
    "    loss = ctc(\n",
    "        model_output, target_sequence, input_lengths, label_lengths)\n",
    "    print(loss.item())\n",
    "    print(orientation)\n",
    "    \n",
    "    greedy_transcript = \" \".join(greedy_decoder(model_output_flattened))\n",
    "    greedy_transcript_2 = \" \".join(greedy_decoder(model_output))\n",
    "\n",
    "    beam_transcript = beam_search_ctc(\n",
    "        model_output_flattened.detach().cpu(), beam_width=20)\n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "    #print(greedy_transcript)\n",
    "    #print(beam_transcript)\n",
    "\n",
    "    decoded_prediction = sort_transcript_reduced_spacers(greedy_transcript)\n",
    "    decoded_prediction_2 = sort_transcript_reduced_spacers(greedy_transcript_2)\n",
    "    search_prediction = sort_transcript(actual_transcript)\n",
    "    original = sort_transcript(\" \".join([str(i) for i in payload]))\n",
    "    print(decoded_prediction)\n",
    "    print(decoded_prediction_2)\n",
    "    print(search_prediction)\n",
    "    print(original)\n",
    "    \n",
    "    found_motifs_caller = evaluate_prediction(decoded_prediction, original)\n",
    "    found_motifs_search = evaluate_prediction(search_prediction, original)\n",
    "    print(found_motifs_caller)\n",
    "    print(found_motifs_search)\n",
    "    sum_diff += found_motifs_caller[0] - found_motifs_search[0]\n",
    "    \n",
    "    #greedy_ratio = ratio(greedy_transcript, actual_transcript)\n",
    "    #beam_ratio = ratio(beam_transcript, actual_transcript)\n",
    "    #sum_diff += beam_ratio - greedy_ratio\n",
    "    #print()\n",
    "    counter+=1\n",
    "    print(sum_diff)\n",
    "    print()\n",
    "\n",
    "    if counter == 5:\n",
    "        print(sum_diff)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction(\n",
    "        squiggle: list[float], model: NaiveCaller, beam: bool, beam_width: int = 30) -> List[List[int]]:\n",
    "\n",
    "    input_sequence = torch.tensor(\n",
    "                squiggle, dtype=torch.float32)\n",
    "    input_sequence = input_sequence.view(\n",
    "        1, 1, len(squiggle)).to(device)\n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)\n",
    "    \n",
    "    model_output_flattened = model_output.view(\n",
    "    model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "\n",
    "    if beam:\n",
    "        transcript = beam_search_ctc(\n",
    "        model_output_flattened.detach().cpu(), beam_width=beam_width)\n",
    "    else:\n",
    "        transcript = \" \".join(greedy_decoder(model_output_flattened))\n",
    "\n",
    "    return sort_transcript_reduced_spacers(transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_motif_tallies(motif_tallies: List[List[int]], payload_cycles: List[List[int]]) -> Tuple[float, float]:\n",
    "    \n",
    "    correct = 0\n",
    "    errs = 0\n",
    "    for tallies, cycle in zip(motif_tallies, payload_cycles):\n",
    "        sorted_tallies = sorted(range(len(tallies)), key=lambda i: tallies[i], reverse=True)\n",
    "        top_4 = [i+1 for i in sorted_tallies[:4]]\n",
    "\n",
    "\n",
    "        correct += len(set(top_4).intersection(set(cycle)))\n",
    "        errs += len(set(top_4) - set(cycle))\n",
    "\n",
    "    return correct / 32, errs / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1096206df8034946971fa8dd922887a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search acc 0.8125 err 0.1875\n",
      "Caller acc 0.65625 err 0.34375\n"
     ]
    }
   ],
   "source": [
    "# Testing convergence\n",
    "for barcode in merged_df['ONT_Barcode'].unique():\n",
    "    for cycle in merged_df['HW_Address'].unique():\n",
    "\n",
    "        motif_tallies_search = [[0 for i in range(8)] for i in range(8)]\n",
    "        motif_tallies_caller = [[0 for i in range(8)] for i in range(8)]\n",
    "\n",
    "        selected_df = merged_df.loc[\n",
    "            (merged_df['ONT_Barcode'] == barcode) &\n",
    "            (merged_df['HW_Address'] == cycle) &\n",
    "            (merged_df['orientation'].str.startswith('+'))       \n",
    "        ]\n",
    "        payload = selected_df['Payload'].tolist()[0]\n",
    "        squiggles = selected_df['squiggle'].tolist()\n",
    "        search_predictions = [\n",
    "            sort_transcript(i) for i in selected_df['Spacer_Sequence'].tolist()]\n",
    "        orientations = selected_df['orientation']\n",
    "        \n",
    "        for squiggle, search_prediction in tqdm(zip(\n",
    "            squiggles[:30], search_predictions), total=len(squiggles)):\n",
    "            \n",
    "            decoded_prediction = get_model_prediction(squiggle, model, beam=False)\n",
    "            \n",
    "\n",
    "            for i in range(len(search_prediction)):\n",
    "                for j, k in zip(search_prediction[i], decoded_prediction[i]):\n",
    "                    motif_tallies_search[i][j-1] += 1\n",
    "                    motif_tallies_caller[i][k-1] += 1\n",
    "\n",
    "        \n",
    "        search_acc, search_err = evaluate_motif_tallies(motif_tallies_search, payload)\n",
    "        caller_acc, caller_err = evaluate_motif_tallies(motif_tallies_caller, payload)\n",
    "\n",
    "        print(f\"Search acc {search_acc} err {search_err}\\n\"\n",
    "              f\"Caller acc {caller_acc} err {caller_err}\")\n",
    "        \n",
    "        break\n",
    "        \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
