{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller, NaiveCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from greedy_decoder import GreedyCTCDecoder\n",
    "from Levenshtein import ratio\n",
    "from utils import load_model, get_metrics_for_evaluation, sort_transcript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from beam_search_decoder import beam_search_ctc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 19\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\empirical\\filtered_model.pth\"\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\empirical\\forward.pth\"\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels = labels)\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "model = load_model(model_path=model_path, device=device, n_classes=n_classes)\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\pickled_datasets\\28_2_25.pkl\"\n",
    "test_dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\datasets\\empirical\\full_empirical_test_dataset_v5_payload_seq.pkl\"\n",
    "#dataset = pd.read_pickle(dataset_path)\n",
    "#dataset = pd.read_pickle(test_dataset_path)\n",
    "\n",
    "#X, y, payloads = load_training_data(\n",
    "#        test_dataset_path, column_x='squiggle', column_y='motif_seq', payload=True, sampling_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, payloads = load_training_data(\n",
    "        test_dataset_path, column_x='squiggle', column_y='Spacer_Sequence', payload=True, sampling_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, payloads_train, payloads_test = train_test_split(\n",
    "        X, payloads, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction(prediction, original):\n",
    "\n",
    "    found = 0\n",
    "    err = 0\n",
    "    for i, j in zip(prediction, original):\n",
    "        for k in range(len(i)):\n",
    "            if i[k] in j:\n",
    "                found += 1\n",
    "            else:\n",
    "                err += 1\n",
    "\n",
    "    return found, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e31408c0e242f18583d0526310cf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9585866928100586\n",
      "(3, 1)\n",
      "(4, 0)\n",
      "-1\n",
      "\n",
      "17.379819869995117\n",
      "(2, 3)\n",
      "(1, 0)\n",
      "0\n",
      "\n",
      "15.683625221252441\n",
      "(0, 4)\n",
      "(1, 0)\n",
      "-1\n",
      "\n",
      "7.839217185974121\n",
      "(2, 2)\n",
      "(2, 0)\n",
      "-1\n",
      "\n",
      "6.514053821563721\n",
      "(4, 1)\n",
      "(2, 0)\n",
      "1\n",
      "\n",
      "8.028848648071289\n",
      "(4, 0)\n",
      "(5, 0)\n",
      "0\n",
      "\n",
      "8.212181091308594\n",
      "(2, 2)\n",
      "(2, 0)\n",
      "0\n",
      "\n",
      "16.8619441986084\n",
      "(1, 4)\n",
      "(1, 0)\n",
      "0\n",
      "\n",
      "16.176551818847656\n",
      "(2, 2)\n",
      "(1, 0)\n",
      "1\n",
      "\n",
      "2.840304136276245\n",
      "(2, 2)\n",
      "(3, 0)\n",
      "0\n",
      "\n",
      "16.70201301574707\n",
      "(1, 4)\n",
      "(1, 0)\n",
      "0\n",
      "\n",
      "12.562923431396484\n",
      "(2, 2)\n",
      "(1, 0)\n",
      "1\n",
      "\n",
      "10.590460777282715\n",
      "(1, 4)\n",
      "(3, 0)\n",
      "-1\n",
      "\n",
      "6.689669132232666\n",
      "(2, 2)\n",
      "(5, 0)\n",
      "-4\n",
      "\n",
      "15.859752655029297\n",
      "(5, 0)\n",
      "(1, 0)\n",
      "0\n",
      "\n",
      "4.709817409515381\n",
      "(2, 3)\n",
      "(4, 0)\n",
      "-2\n",
      "\n",
      "13.006366729736328\n",
      "(1, 4)\n",
      "(1, 0)\n",
      "-2\n",
      "\n",
      "8.198397636413574\n",
      "(3, 2)\n",
      "(3, 0)\n",
      "-2\n",
      "\n",
      "18.26764488220215\n",
      "(2, 3)\n",
      "(1, 0)\n",
      "-1\n",
      "\n",
      "18.063770294189453\n",
      "(0, 5)\n",
      "(1, 0)\n",
      "-2\n",
      "\n",
      "7.439448356628418\n",
      "(4, 0)\n",
      "(5, 2)\n",
      "-3\n",
      "\n",
      "7.183128356933594\n",
      "(2, 2)\n",
      "(2, 0)\n",
      "-3\n",
      "\n",
      "4.571244239807129\n",
      "(1, 3)\n",
      "(4, 0)\n",
      "-6\n",
      "\n",
      "14.714981079101562\n",
      "(3, 2)\n",
      "(1, 0)\n",
      "-4\n",
      "\n",
      "13.256802558898926\n",
      "(2, 3)\n",
      "(1, 0)\n",
      "-3\n",
      "\n",
      "5.335145950317383\n",
      "(3, 2)\n",
      "(5, 0)\n",
      "-5\n",
      "\n",
      "2.731339454650879\n",
      "(4, 1)\n",
      "(4, 0)\n",
      "-5\n",
      "\n",
      "6.005348205566406\n",
      "(1, 3)\n",
      "(2, 0)\n",
      "-6\n",
      "\n",
      "18.1879940032959\n",
      "(1, 4)\n",
      "(1, 0)\n",
      "-6\n",
      "\n",
      "16.903892517089844\n",
      "(4, 1)\n",
      "(1, 0)\n",
      "-3\n",
      "\n",
      "10.865744590759277\n",
      "(3, 2)\n",
      "(2, 0)\n",
      "-2\n",
      "\n",
      "6.160274505615234\n",
      "(1, 4)\n",
      "(2, 0)\n",
      "-3\n",
      "\n",
      "16.895235061645508\n",
      "(1, 4)\n",
      "(1, 0)\n",
      "-3\n",
      "\n",
      "5.025509357452393\n",
      "(3, 1)\n",
      "(4, 0)\n",
      "-4\n",
      "\n",
      "5.182835102081299\n",
      "(2, 3)\n",
      "(5, 0)\n",
      "-7\n",
      "\n",
      "17.709842681884766\n",
      "(2, 3)\n",
      "(1, 0)\n",
      "-6\n",
      "\n",
      "7.257765293121338\n",
      "(3, 2)\n",
      "(2, 0)\n",
      "-5\n",
      "\n",
      "10.37102222442627\n",
      "(4, 0)\n",
      "(1, 0)\n",
      "-2\n",
      "\n",
      "6.52630090713501\n",
      "(1, 3)\n",
      "(7, 0)\n",
      "-8\n",
      "\n",
      "4.827482223510742\n",
      "(3, 2)\n",
      "(4, 0)\n",
      "-9\n",
      "\n",
      "13.060853004455566\n",
      "(2, 3)\n",
      "(2, 0)\n",
      "-9\n",
      "\n",
      "16.54920768737793\n",
      "(4, 1)\n",
      "(1, 0)\n",
      "-6\n",
      "\n",
      "6.281572341918945\n",
      "(1, 4)\n",
      "(3, 0)\n",
      "-8\n",
      "\n",
      "8.01154899597168\n",
      "(2, 3)\n",
      "(2, 0)\n",
      "-8\n",
      "\n",
      "18.183164596557617\n",
      "(3, 2)\n",
      "(0, 1)\n",
      "-5\n",
      "\n",
      "7.0791916847229\n",
      "(1, 4)\n",
      "(3, 0)\n",
      "-7\n",
      "\n",
      "17.54831314086914\n",
      "(2, 3)\n",
      "(1, 0)\n",
      "-6\n",
      "\n",
      "7.3382649421691895\n",
      "(3, 2)\n",
      "(3, 0)\n",
      "-6\n",
      "\n",
      "2.6475045680999756\n",
      "(1, 4)\n",
      "(4, 0)\n",
      "-9\n",
      "\n",
      "17.29074478149414\n",
      "(3, 2)\n",
      "(1, 0)\n",
      "-7\n",
      "\n",
      "7.468517303466797\n",
      "(4, 1)\n",
      "(2, 0)\n",
      "-5\n",
      "\n",
      "12.71019172668457\n",
      "(3, 1)\n",
      "(1, 0)\n",
      "-3\n",
      "\n",
      "3.623366117477417\n",
      "(1, 4)\n",
      "(3, 0)\n",
      "-5\n",
      "\n",
      "7.85875940322876\n",
      "(2, 3)\n",
      "(4, 0)\n",
      "-7\n",
      "\n",
      "7.852712631225586\n",
      "(2, 2)\n",
      "(2, 0)\n",
      "-7\n",
      "\n",
      "3.2991392612457275\n",
      "(2, 3)\n",
      "(3, 0)\n",
      "-8\n",
      "\n",
      "9.414609909057617\n",
      "(4, 0)\n",
      "(2, 0)\n",
      "-6\n",
      "\n",
      "5.807397365570068\n",
      "(4, 0)\n",
      "(3, 0)\n",
      "-5\n",
      "\n",
      "4.472084045410156\n",
      "(4, 1)\n",
      "(3, 0)\n",
      "-4\n",
      "\n",
      "11.318471908569336\n",
      "(2, 3)\n",
      "(2, 0)\n",
      "-4\n",
      "\n",
      "18.178598403930664\n",
      "(4, 1)\n",
      "(1, 0)\n",
      "-1\n",
      "\n",
      "6.290289402008057\n",
      "(1, 4)\n",
      "(2, 0)\n",
      "-2\n",
      "\n",
      "5.83036470413208\n",
      "(0, 4)\n",
      "(2, 0)\n",
      "-4\n",
      "\n",
      "12.210404396057129\n",
      "(3, 2)\n",
      "(2, 0)\n",
      "-3\n",
      "\n",
      "16.275287628173828\n",
      "(4, 1)\n",
      "(1, 0)\n",
      "0\n",
      "\n",
      "9.479391098022461\n",
      "(2, 3)\n",
      "(3, 0)\n",
      "-1\n",
      "\n",
      "15.25827407836914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     26\u001b[0m greedy_transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(greedy_decoder(model_output))\n\u001b[1;32m---> 27\u001b[0m beam_transcript \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_search_ctc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_output_flattened\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m actual_transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y])\n\u001b[0;32m     31\u001b[0m decoded_prediction \u001b[38;5;241m=\u001b[39m sort_transcript(greedy_transcript)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\beam_search_decoder.py:62\u001b[0m, in \u001b[0;36mbeam_search_ctc\u001b[1;34m(prob_matrix, beam_width, blank, n_classes, return_alignments)\u001b[0m\n\u001b[0;32m     57\u001b[0m alignments, alignment_probs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, probs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(prob_matrix):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Get the top 3\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# previous_alignments adding - collapse at will - if the same as previous, don't add \u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# If new and the previous is blank, remove the blank\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     top_n \u001b[38;5;241m=\u001b[39m heapq\u001b[38;5;241m.\u001b[39mnlargest(n_classes, \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     63\u001b[0m     top_tokens \u001b[38;5;241m=\u001b[39m [i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_n]\n\u001b[0;32m     64\u001b[0m     top_probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(i[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_n]\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_tensor.py:1057\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[0;32m   1049\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "sum_diff = 0\n",
    "\n",
    "for x, y, payload in tqdm(zip(X_test, y_test, payloads_test), total=len(X_test)):\n",
    "    input_sequence = torch.tensor(\n",
    "        x, dtype=torch.float32)\n",
    "    input_sequence = input_sequence.view(\n",
    "        1, 1, len(x)).to(device)\n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)\n",
    "    \n",
    "    label_lengths = torch.tensor([len(y)])\n",
    "    target_sequence = torch.tensor(y).to(device)\n",
    "\n",
    "    \n",
    "    n_timesteps = model_output.shape[0]\n",
    "    input_lengths = torch.tensor([n_timesteps])\n",
    "    \n",
    "    model_output_flattened = model_output.view(\n",
    "        model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "\n",
    "    loss = ctc(\n",
    "        model_output, target_sequence, input_lengths, label_lengths)\n",
    "    print(loss.item())\n",
    "    \n",
    "    greedy_transcript = \" \".join(greedy_decoder(model_output))\n",
    "    beam_transcript = beam_search_ctc(\n",
    "        model_output_flattened.detach().cpu(), beam_width=20)\n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "\n",
    "    decoded_prediction = sort_transcript(greedy_transcript)\n",
    "    search_prediction = sort_transcript(actual_transcript)\n",
    "    original = sort_transcript(\" \".join([str(i) for i in payload]))\n",
    "    #print(decoded_prediction)\n",
    "    #print(search_prediction)\n",
    "    #print(original)\n",
    "    \n",
    "    found_motifs_caller = evaluate_prediction(decoded_prediction, original)\n",
    "    found_motifs_search = evaluate_prediction(search_prediction, original)\n",
    "    print(found_motifs_caller)\n",
    "    print(found_motifs_search)\n",
    "    sum_diff += found_motifs_caller[0] - found_motifs_search[0]\n",
    "    \n",
    "    #greedy_ratio = ratio(greedy_transcript, actual_transcript)\n",
    "    #beam_ratio = ratio(beam_transcript, actual_transcript)\n",
    "    #sum_diff += beam_ratio - greedy_ratio\n",
    "    #print()\n",
    "    counter+=1\n",
    "    print(sum_diff)\n",
    "    print()\n",
    "\n",
    "    if counter == 200:\n",
    "        print(sum_diff)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 100 /32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
