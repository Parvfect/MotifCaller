{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My guy that's not how load a model\n",
    "n_classes = 17\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\synthetic\\model_27_2_25.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device):\n",
    "    \"\"\"\n",
    "    Loading model purely for inference\n",
    "    Will need to lead optimizer to fine tune\n",
    "    \"\"\"\n",
    "    # Model Definition\n",
    "    model = MotifCaller(n_classes=17)\n",
    "    \n",
    "    if device == torch.device('cpu'):\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        checkpoint = torch.load(model_path)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "    \n",
    "\n",
    "# Load model\n",
    "# device\n",
    "# port these useful methods to utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path=model_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\synthetic\\model_27_2_25.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_savepaths(running_on_hpc=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif_seq</th>\n",
       "      <th>base_seq</th>\n",
       "      <th>squiggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5, 11, 11, 7, 11, 11, 8, 11, 12, 2, 12, 12, 5...</td>\n",
       "      <td>TTTATCGTCGTCACATCAGTCGACATCAGTCGGCATGAAGACACTA...</td>\n",
       "      <td>[504, 506, 491, 502, 504, 515, 458, 472, 458, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[14, 14, 8, 14, 15, 2, 15, 15, 5, 15, 15, 7, 1...</td>\n",
       "      <td>TGACGTCGGATGACGTCGGCAGCGCCACCAACTCCACAAATGACGT...</td>\n",
       "      <td>[469, 480, 479, 479, 481, 482, 483, 498, 505, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10, 10, 3, 10, 10, 7, 10, 11, 2, 11, 11, 4, 1...</td>\n",
       "      <td>GGACAGCTAGGGACAGCTACACCCCCGTATTTTGAGCGGGGGACAG...</td>\n",
       "      <td>[465, 470, 479, 486, 539, 532, 533, 525, 527, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12, 1, 12, 12, 4, 12, 12, 6, 12, 12, 7, 12, 1...</td>\n",
       "      <td>TCGCCTTCATACCCCACTAACGTAGAGTACTGCCCTTCATACCCCT...</td>\n",
       "      <td>[485, 487, 496, 495, 488, 488, 490, 488, 524, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[11, 12, 3, 12, 12, 4, 12, 12, 6, 12, 12, 7, 1...</td>\n",
       "      <td>AGTCGCCTTCATACCCACCCCCGTATTTTGAGCGGCCTTCATACCC...</td>\n",
       "      <td>[544, 556, 539, 547, 536, 534, 538, 493, 488, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           motif_seq  \\\n",
       "0  [5, 11, 11, 7, 11, 11, 8, 11, 12, 2, 12, 12, 5...   \n",
       "1  [14, 14, 8, 14, 15, 2, 15, 15, 5, 15, 15, 7, 1...   \n",
       "2  [10, 10, 3, 10, 10, 7, 10, 11, 2, 11, 11, 4, 1...   \n",
       "3  [12, 1, 12, 12, 4, 12, 12, 6, 12, 12, 7, 12, 1...   \n",
       "4  [11, 12, 3, 12, 12, 4, 12, 12, 6, 12, 12, 7, 1...   \n",
       "\n",
       "                                            base_seq  \\\n",
       "0  TTTATCGTCGTCACATCAGTCGACATCAGTCGGCATGAAGACACTA...   \n",
       "1  TGACGTCGGATGACGTCGGCAGCGCCACCAACTCCACAAATGACGT...   \n",
       "2  GGACAGCTAGGGACAGCTACACCCCCGTATTTTGAGCGGGGGACAG...   \n",
       "3  TCGCCTTCATACCCCACTAACGTAGAGTACTGCCCTTCATACCCCT...   \n",
       "4  AGTCGCCTTCATACCCACCCCCGTATTTTGAGCGGCCTTCATACCC...   \n",
       "\n",
       "                                            squiggle  \n",
       "0  [504, 506, 491, 502, 504, 515, 458, 472, 458, ...  \n",
       "1  [469, 480, 479, 479, 481, 482, 483, 498, 505, ...  \n",
       "2  [465, 470, 479, 486, 539, 532, 533, 525, 527, ...  \n",
       "3  [485, 487, 496, 495, 488, 488, 490, 488, 524, ...  \n",
       "4  [544, 556, 539, 547, 536, 534, 538, 493, 488, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['motif_seq', 'base_seq', 'squiggle'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2997/2997 [00:01<00:00, 2404.57it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path, model_save_path, file_write_path = get_savepaths(\n",
    "        running_on_hpc=False)\n",
    "\n",
    "X, y = load_training_data(\n",
    "        dataset_path, column_x='squiggle', column_y='motif_seq',\n",
    "        sampling_rate=0.3)\n",
    "\n",
    "X = data_preproc(\n",
    "    X=X, window_size=1024, step_size=800, normalize_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import torch.nn as nn\n",
    "\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for x_, y_ in zip(X, y):\n",
    "    x_ = torch.tensor(x_, dtype=torch.float32).to(device)\n",
    "    model_output = model(x_)\n",
    "    model_output = model_output.permute(0, 1, 2).view(\n",
    "        model_output.shape[1] * model_output.shape[0], n_classes)\n",
    "    \n",
    "    label_lengths = torch.tensor(len(y_))\n",
    "    y_ = torch.tensor(y_).to(device)\n",
    "    \n",
    "    n_timesteps = model_output.shape[0]\n",
    "    input_lengths = torch.tensor(n_timesteps)\n",
    "    \n",
    "    loss = ctc(\n",
    "        model_output, y_, input_lengths, label_lengths)\n",
    "    #print(loss.item())\n",
    "\n",
    "    if loss.item() < 2:\n",
    "        print(np.exp(model_output.sum(axis=0).cpu().detach().numpy()))\n",
    "    \n",
    "    counter += 1\n",
    "    if counter == 2000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_config import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    n_classes=n_classes, hidden_size=256, window_size=1024, window_step=800, train_epochs=50, device=device,\n",
    "    model_save_path=\"\", write_path=\"\", dataset='synthetic', windows=True, sampling_rate=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_loop import run_epoch\n",
    "import torch.optim as optim\n",
    "from greedy_decoder import GreedyCTCDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_epoch() missing 2 required positional arguments: 'optimizer' and 'decoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: run_epoch() missing 2 required positional arguments: 'optimizer' and 'decoder'"
     ]
    }
   ],
   "source": [
    "result_dict = run_epoch(\n",
    "    model=model, model_config=model_config, X=X, y=y, ctc=ctc,\n",
    "    optimizer=optimizer, greedy_decoder=greedy_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
