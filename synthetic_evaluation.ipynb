{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller, NaiveCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from greedy_decoder import GreedyCTCDecoder\n",
    "from Levenshtein import ratio\n",
    "from utils import load_model, get_metrics_for_evaluation, sort_transcript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from beam_search_decoder import beam_search_ctc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 17\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\synthetic\\0.5_right.pth\"\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels = labels)\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveCaller(num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveCaller(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(4, 16, kernel_size=(5,), stride=(3,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=5, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv1d(16, 64, kernel_size=(5,), stride=(1,))\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(128, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['cnn.0.weight', 'cnn.0.bias', 'cnn.3.weight', 'cnn.3.bias', 'cnn.6.weight', 'cnn.6.bias', 'cnn.8.weight', 'cnn.8.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'lstm.weight_ih_l1', 'lstm.weight_hh_l1', 'lstm.bias_ih_l1', 'lstm.bias_hh_l1', 'lstm.weight_ih_l1_reverse', 'lstm.weight_hh_l1_reverse', 'lstm.bias_ih_l1_reverse', 'lstm.bias_hh_l1_reverse', 'lstm.weight_ih_l2', 'lstm.weight_hh_l2', 'lstm.bias_ih_l2', 'lstm.bias_hh_l2', 'lstm.weight_ih_l2_reverse', 'lstm.weight_hh_l2_reverse', 'lstm.bias_ih_l2_reverse', 'lstm.bias_hh_l2_reverse', 'fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(model_path)\n",
    "print(checkpoint['model_state_dict'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "model = load_model(model_path=model_path, device=device, n_classes=n_classes)\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\synthetic\\pickled_datasets\\big_synth_5_3_25.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaiveCaller(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv1d(4, 16, kernel_size=(5,), stride=(3,))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool1d(kernel_size=5, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv1d(16, 64, kernel_size=(5,), stride=(1,))\n",
       "    (7): ReLU()\n",
       "    (8): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
       "    (9): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(128, 256, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif_seq</th>\n",
       "      <th>base_seq</th>\n",
       "      <th>squiggle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6, 12, 13, 2, 13, 13, 3, 13, 13, 5, 13, 13, 7...</td>\n",
       "      <td>ACTGGTGTAGTCACTGATTGACACATCAACATAAAAAGCTGTTACT...</td>\n",
       "      <td>[525, 525, 508, 521, 520, 521, 530, 519, 465, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10, 10, 7, 10, 10, 8, 10, 11, 1, 11, 11, 2, 1...</td>\n",
       "      <td>CACTGATTGAAGTCGATCGAAGTCGATCGGGGGTCGCTATAGAGTA...</td>\n",
       "      <td>[512, 506, 510, 512, 510, 512, 514, 508, 517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5, 13, 13, 7, 13, 14, 1, 14, 14, 4, 14, 14, 7...</td>\n",
       "      <td>GCTAGAAGTTCTGTAGGTCCCGCATAAAAAGCTATAAAAAGCTGGG...</td>\n",
       "      <td>[513, 515, 513, 506, 469, 480, 483, 485, 481, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[8, 9, 10, 1, 10, 10, 2, 10, 10, 3, 10, 10, 7,...</td>\n",
       "      <td>AGTGGACTCGCGGCCTTAGCTAAGTCGATCGAGGCATTCGCCAGGA...</td>\n",
       "      <td>[537, 534, 535, 535, 538, 545, 544, 464, 492, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[15, 5, 15, 15, 8, 15, 16, 1, 16, 16, 4, 16, 1...</td>\n",
       "      <td>GACTAGTACAGAAGTTCTGTAGGTCCCGCAGACTAGTACAGACTAG...</td>\n",
       "      <td>[493, 503, 501, 510, 502, 490, 505, 507, 500, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           motif_seq  \\\n",
       "0  [6, 12, 13, 2, 13, 13, 3, 13, 13, 5, 13, 13, 7...   \n",
       "1  [10, 10, 7, 10, 10, 8, 10, 11, 1, 11, 11, 2, 1...   \n",
       "2  [5, 13, 13, 7, 13, 14, 1, 14, 14, 4, 14, 14, 7...   \n",
       "3  [8, 9, 10, 1, 10, 10, 2, 10, 10, 3, 10, 10, 7,...   \n",
       "4  [15, 5, 15, 15, 8, 15, 16, 1, 16, 16, 4, 16, 1...   \n",
       "\n",
       "                                            base_seq  \\\n",
       "0  ACTGGTGTAGTCACTGATTGACACATCAACATAAAAAGCTGTTACT...   \n",
       "1  CACTGATTGAAGTCGATCGAAGTCGATCGGGGGTCGCTATAGAGTA...   \n",
       "2  GCTAGAAGTTCTGTAGGTCCCGCATAAAAAGCTATAAAAAGCTGGG...   \n",
       "3  AGTGGACTCGCGGCCTTAGCTAAGTCGATCGAGGCATTCGCCAGGA...   \n",
       "4  GACTAGTACAGAAGTTCTGTAGGTCCCGCAGACTAGTACAGACTAG...   \n",
       "\n",
       "                                            squiggle  \n",
       "0  [525, 525, 508, 521, 520, 521, 530, 519, 465, ...  \n",
       "1  [512, 506, 510, 512, 510, 512, 514, 508, 517, ...  \n",
       "2  [513, 515, 513, 506, 469, 480, 483, 485, 481, ...  \n",
       "3  [537, 534, 535, 535, 538, 545, 544, 464, 492, ...  \n",
       "4  [493, 503, 501, 510, 502, 490, 505, 507, 500, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_training_data(\n",
    "       dataset_path, column_x='squiggle', column_y='motif_seq', payload=False, sampling_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_cycle_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce58ad84e1044fd6bfcbe98409086a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0232558139534884\n",
      "[[], [], [5, 7], [1, 2, 3, 6], [4, 5, 7, 8], [2, 5, 7, 8], [], []]\n",
      "\n",
      "[[], [], [5, 8], [1, 4, 5, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [5, 8], [1, 2, 5, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [6, 8], [1, 4, 5, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [5, 8], [2, 4, 5, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [5, 8], [1, 5, 5, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [5, 8], [1, 4, 5, 8], [1, 4, 6, 8], [1, 4, 5, 8], [], []]\n",
      "[[], [], [5, 8], [1, 4, 5, 8], [1, 4, 7, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [5, 8], [1, 4, 6, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n",
      "[[], [], [5, 8], [1, 4, 5, 8], [1, 4, 6, 8], [1, 4, 6, 8], [], []]\n",
      "[[], [], [6, 8], [1, 2, 5, 8], [1, 4, 6, 8], [1, 4, 7, 8], [], []]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "sum_diff = 0\n",
    "\n",
    "for x, y in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
    "    \n",
    "    input_sequence = normalize([x], norm='l1')\n",
    "    input_sequence = torch.tensor(\n",
    "        input_sequence, dtype=torch.float32)\n",
    "    input_sequence = input_sequence.view(\n",
    "        1, 1, len(x)).to(device)\n",
    "    \n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)\n",
    "    \n",
    "    label_lengths = torch.tensor([len(y)])\n",
    "    target_sequence = torch.tensor(y).to(device)\n",
    "\n",
    "    n_timesteps = model_output.shape[0]\n",
    "    print(n_timesteps/len(target_sequence))\n",
    "    input_lengths = torch.tensor([n_timesteps])    \n",
    "    model_output_flattened = model_output.view(\n",
    "        model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "\n",
    "    loss = ctc(\n",
    "        model_output, target_sequence, input_lengths, label_lengths)\n",
    "    \n",
    "\n",
    "    if loss.item() > 1:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    greedy_transcript = \" \".join(greedy_decoder(model_output))\n",
    "    beam_transcript = beam_search_ctc(\n",
    "        model_output_flattened.detach().cpu(), beam_width=10, return_alignments=True)\n",
    "    \n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "\n",
    "    print(sort_transcript(actual_transcript))\n",
    "    print()\n",
    "\n",
    "    t = [sort_transcript(i) for i in beam_transcript]\n",
    "\n",
    "    \n",
    "    for i in t:\n",
    "        print(i)\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "    #print()\n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "\n",
    "    #print(greedy_transcript)\n",
    "    #print(actual_transcript)\n",
    "\n",
    "    decoded_prediction = sort_transcript(beam_transcript)\n",
    "    search_prediction = sort_transcript(actual_transcript)\n",
    "    n_motifs = sum([len(i) for i in search_prediction])\n",
    "    #print(decoded_prediction)\n",
    "    #print(search_prediction)\n",
    "    if n_motifs == 0:\n",
    "        continue\n",
    "\n",
    "    found_motifs_caller = evaluate_cycle_prediction(decoded_prediction, search_prediction)\n",
    "    print(found_motifs_caller)\n",
    "    print()\n",
    "    \n",
    "    #greedy_ratio = ratio(greedy_transcript, actual_transcript)\n",
    "    #beam_ratio = ratio(beam_transcript, actual_transcript)\n",
    "    #sum_diff += beam_ratio - greedy_ratio\n",
    "\n",
    "    counter += 1\n",
    "    if counter == 50:\n",
    "        print(sum_diff)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
