{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller, NaiveCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from greedy_decoder import GreedyCTCDecoder\n",
    "from Levenshtein import ratio\n",
    "from utils import load_model, get_metrics_for_evaluation, sort_transcript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from beam_search_decoder import beam_search_ctc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 17\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\models\\synthetic\\50_epochs.pth\"\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels = labels)\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "model = load_model(model_path=model_path, device=device, n_classes=n_classes)\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\synthetic\\pickled_datasets\\25_2_25.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_training_data(\n",
    "       dataset_path, column_x='squiggle', column_y='motif_seq', payload=False, sampling_rate=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_cycle_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130bdaaa1b1742dbad5db32233d3d7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 6 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "3 13 13 5 13 13 6 13 14 2 14 14 3 14 14 4 14 14 8 14 15 2 15 15 3 15 15 5 15 15 6 15 16 2 16 16 4 16 16 5 16 16 7 16\n",
      "(0.3333333333333333, 0.6)\n",
      "\n",
      "10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 2 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "9 10 1 10 10 2 10 10 4 10 10 8 10 11 3 11 11 4 11 11 5 11 11 6 11 12 2 12 12 3 12 12 5 12 12 6 12 13 1 13 13 3 13 13 4 13 13 7 13 14 1 14 14 3 14 14 4 14 14 7 14 15 2 15 15 5 15 15 7 15 15 8 15 16 1 16 16 6 16 16 7 16 16 8 16\n",
      "(0.5416666666666666, 0.4583333333333333)\n",
      "\n",
      "14 14 3 14 14 5 14 14 8 14 15 1 15 15 4 15 15 5 15 15 7 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "14 14 3 14 14 4 14 14 7 14 15 1 15 15 2 15 15 3 15 15 8 15 16 3 16 16 5 16 16 6 16 16 8 16\n",
      "(0.45454545454545453, 0.5454545454545454)\n",
      "\n",
      "2 15 15 3 15 15 6 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "15 1 15 15 3 15 15 6 15 15 7 15 16 4 16 16 5 16 16 6 16 16 7 16\n",
      "(0.375, 0.625)\n",
      "\n",
      "7 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "2 9 9 3 9 9 5 9 9 8 9 10 1 10 10 2\n",
      "13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "13 13 2 13 13 5 13 13 6 13 14 4 14 14 5 14 14 6 14 14 7 14 15 2 15 15 3 15 15 4 15 15 8 15 16 1 16 16 3 16 16 4 16 16 6 16\n",
      "(0.4666666666666667, 0.5333333333333333)\n",
      "\n",
      "14 15 1 15 15 3 15 15 6 15 15 8 15 16 1 16 16 4 16 16 6 16 16 8 16\n",
      "15 1 15 15 3 15 15 6 15 15 7 15 16 2 16 16 3 16 16 5 16 16 7 16\n",
      "(0.375, 0.625)\n",
      "\n",
      "3 15 11 7 11 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "5 15 15 8 15 16 1 16 16 5 16 16 6 16 16 7 16\n",
      "(0.3333333333333333, 0.6666666666666666)\n",
      "\n",
      "9 3 9 9 6 9 9 8 9 10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 2 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "3 9 9 4 9 9 5 9 10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 2 11 11 4 11 11 6 11 12 1 12 12 2 12 12 3 12 12 6 12 13 2 13 13 3 13 13 4 13 13 5 13 14 1 14 14 2 14 14 4 14 14 5 14 15 1 15 15 3 15 15 6 15 15 7 15 16 3 16 16 4 16 16 5 16 16 6 16\n",
      "(0.5, 0.5)\n",
      "\n",
      "5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 6 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "12 12 6 12 12 8 12 13 2 13 13 3 13 13 4 13 13 5 13 14 1 14 14 5 14 14 6 14 14 8 14 15 3 15 15 4 15 15 5 15 15 6 15 16 1 16 16 3 16 16 4 16 16 6 16\n",
      "(0.6111111111111112, 0.3888888888888889)\n",
      "\n",
      "3 15 15 5 15 15 7 15 16 2 16 16 4 16 16 6 16 16 8 16\n",
      "5 15 15 6 15 15 8 15 16 1 16 16 2 16 16 4 16 16 6 16\n",
      "(0.5714285714285714, 0.42857142857142855)\n",
      "\n",
      "8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "8 13 14 1 14 14 4 14 14 5 14 14 8 14 15 2 15 15 3 15 15 5 15 15 6 15 16 2 16 16 3 16 16 6 16 16 7 16\n",
      "(0.6153846153846154, 0.38461538461538464)\n",
      "\n",
      "10 11 1 11 11 3 11 11 5 11 11 8 11 12 1 12 12 3 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "6 10 10 7 10 11 1 11 11 6 11 11 7 11 11 8 11 12 1 12 12 2 12 12 4 12 12 5 12 13 1 13 13 4 13 13 5 13 13 7 13 14 4 14 14 6 14 14 7 14 14 8 14 15 1 15 15 3 15 15 4 15 15 7 15 16 1 16 16 2 16 16 7 16 16 8 16\n",
      "(0.4583333333333333, 0.5416666666666666)\n",
      "\n",
      "11 3 11 11 5 11 11 8 11 12 1 12 12 3 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "11 4 11 11 5 11 11 7 11 12 2 12 12 3 12 12 5 12 12 8 12 13 1 13 13 2 13 13 5 13 13 8 13 14 4 14 14 5 14 14 7 14 14 8 14 15 1 15 15 3 15 15 5 15 15 7 15 16 1 16 16 2 16 16 5 16 16 8 16\n",
      "(0.6086956521739131, 0.391304347826087)\n",
      "\n",
      "8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 6 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "5 12 13 1 13 13 2 13 13 3 13 13 6 13 14 2 14 14 3 14 14 6 14 14 7 14 15 3 15 15 4 15 15 6 15 15 7 15 16 2 16 16 3 16 16 4 16 16 7 16\n",
      "(0.35294117647058826, 0.6470588235294118)\n",
      "\n",
      "12 12 3 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "5 12 12 7 12 12 8 12 13 4 13 13 6 13 13 7 13 13 8 13 14 2 14 14 4 14 14 7 14 14 8 14 15 1 15 15 2 15 15 4 15 15 8 15 16 1 16 16 4 16 16 5 16 16 7 16\n",
      "(0.3684210526315789, 0.631578947368421)\n",
      "\n",
      "2 15 15 5 15 15 7 15 16 2 16 16 4 16 16 6 16 16 8 16\n",
      "15 4 15 15 5 15 15 6 15 16 1 16 16 5 16 16 7 16 16 8 16\n",
      "(0.2857142857142857, 0.7142857142857143)\n",
      "\n",
      "9 10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 2 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "9 7 9 10 2 10 10 5 10 10 6 10 10 7 10 11 1 11 11 4 11 11 6 11 11 8 11 12 4 12 12 5 12 12 6 12 12 8 12 13 3 13 13 4 13 13 5 13 13 6 13 14 1 14 14 2 14 14 5 14 14 8 14 15 2 15 15 5 15 15 7 15 15 8 15 16 2 16 16 5 16 16 6 16 16 7 16\n",
      "(0.5416666666666666, 0.4583333333333333)\n",
      "\n",
      "1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 4 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "1 14 14 3 14 14 5 14 14 7 14 15 3 15 15 4 15 15 7 15 15 8 15 16 3 16 16 4 16 16 5 16 16 8 16\n",
      "(0.5833333333333334, 0.4166666666666667)\n",
      "\n",
      "8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 6 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "12 13 2 13 13 5 13 13 6 13 13 7 13 14 1 14 14 5 14 14 7 14 14 8 14 15 1 15 15 2 15 15 4 15 15 7 15 16 3 16 16 5 16 16 6 16 16 8 16\n",
      "(0.4375, 0.625)\n",
      "\n",
      "14 15 1 15 15 3 15 15 6 15 15 8 15 16 1 16 16 4 16 16 6 16 16 8 16\n",
      "8 14 15 1 15 15 3 15 15 6 15 15 7 15 16 1 16 16 3 16 16 4 16 16 6 16\n",
      "(0.6666666666666666, 0.2222222222222222)\n",
      "\n",
      "10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 2 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "10 2 10 10 4 10 10 7 10 10 8 10 11 1 11 11 3 11 11 4 11 11 5 11 12 1 12 12 5 12 12 6 12 12 8 12 13 1 13 13 2 13 13 4 13 13 7 13 14 5 14 14 6 14 14 7 14 14 8 14 15 3 15 15 4 15 15 6 15 15 7 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "(0.5833333333333334, 0.4166666666666667)\n",
      "\n",
      "10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 3 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "3 10 10 7 10 10 8 10 11 4 11 11 5 11 11 6 11 11 8 11 12 3 12 12 5 12 12 6 12 12 8 12 13 2 13 13 4 13 13 6 13 13 7 13 14 2 14 14 4 14 14 5 14 14 7 14 15 4 15 15 5 15 15 7 15 15 8 15 16 1 16 16 4 16 16 5 16 16 7 16\n",
      "(0.4166666666666667, 0.5833333333333334)\n",
      "\n",
      "9 1 9 9 3 9 9 6 9 9 8 9 10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 2 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "9 3 9 9 5 9 9 6 9 9 7 9 10 1 10 10 3 10 10 6 10 10 7 10 11 1 11 11 4 11 11 5 11 11 8 11 12 2 12 12 4 12 12 5 12 12 7 12 13 3 13 13 4 13 13 6 13 13 8 13 14 1 14 14 4 14 14 5 14 14 6 14 15 1 15 15 2 15 15 3 15 15 7 15 16 2 16 16 4 16 16 7 16 16 8 16\n",
      "(0.5416666666666666, 0.4583333333333333)\n",
      "\n",
      "10 10 6 10 10 8 10 11 1 11 11 3 11 11 5 11 11 8 11 12 1 12 12 3 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "4 10 10 6 10 10 7 10 11 2 11 11 3 11 11 4 11 11 6 11 12 2 12 12 4 12 12 5 12 12 8 12 13 2 13 13 3 13 13 6 13 13 7 13 14 1 14 14 3 14 14 5 14 14 6 14 15 3 15 15 4 15 15 6 15 15 7 15 16 1 16 16 4 16 16 6 16 16 8 16\n",
      "(0.4583333333333333, 0.5416666666666666)\n",
      "\n",
      "12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 6 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "12 4 12 12 7 12 12 8 12 13 2 13 13 3 13 13 6 13 13 7 13 14 2 14 14 3 14 14 5 14 14 7 14 15 2 15 15 3 15 15 4 15 15 5 15 16 3 16 16 6 16\n",
      "(0.4117647058823529, 0.5882352941176471)\n",
      "\n",
      "12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 6 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "5 12 13 2 13 13 3 13 13 5 13 13 8 13 14 1 14 14 2 14 14 3 14 14 7 14 15 1 15 15 2 15 15 3 15 15 6 15 16 1 16 16 2 16 16 7 16 16 8 16\n",
      "(0.5294117647058824, 0.4117647058823529)\n",
      "\n",
      "13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "2 13 13 5 13 13 6 13 14 1 14 14 3 14 14 4 14 14 8 14 15 2 15 15 3 15 15 5 15 15 6 15 16 2 16 16 4 16 16 6 16 16 8 16\n",
      "(0.5333333333333333, 0.4666666666666667)\n",
      "\n",
      "14 14 3 14 14 5 14 14 8 14 15 1 15 15 4 15 15 5 15 15 7 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "14 14 5 14 14 6 14 14 7 14 15 3 15 15 4 15 15 6 15 15 8 15 16 3 16 16 4 16 16 7 16 16 8 16\n",
      "(0.36363636363636365, 0.6363636363636364)\n",
      "\n",
      "10 1 10 10 3 10 10 6 10 10 8 10 11 1 11 11 4 11 11 5 11 11 8 11 12 1 12 12 3 12 12 5 12 12 8 12 13 1 13 13 3 13 13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 5 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "3 10 10 4 10 10 5 10 10 8 10 11 2 11 11 3 11 11 4 11 11 7 11 12 2 12 12 3 12 12 6 12 12 8 12 13 1 13 13 2 13 13 3 13 13 5 13 14 1 14 14 2 14 14 5 14 14 7 14 15 1 15 15 3 15 15 4 15 15 6 15 16 2 16 16 3 16 16 6 16 16 8 16\n",
      "(0.5416666666666666, 0.4583333333333333)\n",
      "\n",
      "13 5 13 13 8 13 14 1 14 14 3 14 14 5 14 14 8 14 15 1 15 15 3 15 15 6 15 15 8 15 16 1 16 16 3 16 16 6 16 16 8 16\n",
      "13 5 13 13 6 13 14 1 14 14 4 14 14 5 14 14 7 14 15 1 15 15 2 15 15 5 15 15 8 15 16 1 16 16 2 16 16 4 16 16 5 16\n",
      "(0.42857142857142855, 0.5714285714285714)\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "sum_diff = 0\n",
    "\n",
    "for x, y in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
    "    \n",
    "    input_sequence = normalize([x], norm='l1')\n",
    "    input_sequence = torch.tensor(\n",
    "        input_sequence, dtype=torch.float32)\n",
    "    input_sequence = input_sequence.view(\n",
    "        1, 1, len(x)).to(device)\n",
    "    \n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)\n",
    "    \n",
    "    label_lengths = torch.tensor([len(y)])\n",
    "    target_sequence = torch.tensor(y).to(device)\n",
    "\n",
    "    n_timesteps = model_output.shape[0]\n",
    "    input_lengths = torch.tensor([n_timesteps])    \n",
    "    model_output_flattened = model_output.view(\n",
    "        model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "\n",
    "    loss = ctc(\n",
    "        model_output, target_sequence, input_lengths, label_lengths)\n",
    "    #print(loss.item())\n",
    "    \n",
    "    greedy_transcript = \" \".join(greedy_decoder(model_output))\n",
    "    #beam_transcript = beam_search_ctc(\n",
    "    #    model_output_flattened.detach().cpu(), beam_width=10)\n",
    "    #print()\n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "\n",
    "    print(greedy_transcript)\n",
    "    print(actual_transcript)\n",
    "\n",
    "    decoded_prediction = sort_transcript(greedy_transcript)\n",
    "    search_prediction = sort_transcript(actual_transcript)\n",
    "    n_motifs = sum([len(i) for i in search_prediction])\n",
    "    #print(decoded_prediction)\n",
    "    #print(search_prediction)\n",
    "    if n_motifs == 0:\n",
    "        continue\n",
    "\n",
    "    found_motifs_caller = evaluate_cycle_prediction(decoded_prediction, search_prediction)\n",
    "    print(found_motifs_caller)\n",
    "    print()\n",
    "    \n",
    "    #greedy_ratio = ratio(greedy_transcript, actual_transcript)\n",
    "    #beam_ratio = ratio(beam_transcript, actual_transcript)\n",
    "    #sum_diff += beam_ratio - greedy_ratio\n",
    "\n",
    "    counter += 1\n",
    "    if counter == 30:\n",
    "        print(sum_diff)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
