{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from nn import MotifCaller, NaiveCaller\n",
    "from training_data import data_preproc, load_training_data\n",
    "from utils import get_savepaths, load_model\n",
    "from Bio import Align\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from greedy_decoder import GreedyCTCDecoder\n",
    "from Levenshtein import ratio\n",
    "from utils import load_model, get_metrics_for_evaluation, sort_transcript\n",
    "from sklearn.model_selection import train_test_split\n",
    "from beam_search_decoder import beam_search_ctc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 9\n",
    "model_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\training_logs\\20250325.123145.630545\\model.pth\"\n",
    "labels_int = np.arange(n_classes).tolist()\n",
    "labels = [f\"{i}\" for i in labels_int] # Tokens to be fed into greedy decoder\n",
    "greedy_decoder = GreedyCTCDecoder(labels = labels)\n",
    "ctc = nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_device(device)\n",
    "model = load_model(model_path=model_path, device=device, n_classes=n_classes, hidden_size=256)\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\synthetic\\pickled_datasets\\no_spacers_long.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8580\n",
      "Selected 8580 forward reads\n"
     ]
    }
   ],
   "source": [
    "X, y = load_training_data(\n",
    "       dataset_path, column_x='squiggle', column_y='motif_seq', payload=False, sampling_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 858/858 [00:01<00:00, 833.95it/s]\n"
     ]
    }
   ],
   "source": [
    "X = data_preproc(X, window_size=1000, step_size=300, normalize_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_cycle_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = Align.PairwiseAligner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403b0d1d10294bca960e953e1d789aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/172 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([61, 1, 1000])\n",
      "torch.Size([15, 61, 9])\n",
      "torch.Size([915, 9])\n",
      "21.253889083862305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\beam_search_decoder.py:31: RuntimeWarning: divide by zero encountered in log\n",
      "  new_prob = np.log(np.exp(old_prob) + np.exp(alignment_probs[ind] + prob))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 1 1 3 6 1 4 6 7 5 8 4 4 4 4 4 3 3 2 8 1 7 3 7 8 2 3 6 5 5 3 2 4 7 5 7 3 6 4 4 5 6 2 2 2 4 6 8 2 6 8 7 1 8 4 6 7 8 2 7 4 5 8 6 6 5 7 5 1 1\n",
      "444444444\n",
      "0.0\n",
      "0.11842105263157898\n",
      "torch.Size([67, 1, 1000])\n",
      "torch.Size([15, 67, 9])\n",
      "torch.Size([1005, 9])\n",
      "18.527786254882812\n",
      "8 5 4 6 2 1 3 3 7 4 1 3 8 5 7 2 1 7 3 2 6 2 1 4 6 4 6 6 3 2 6 1 8 3 4 3 3 5 7 8 3 7 5 5 1 8 5 8 6 7 4 1 1 5 6 8 7 7 8 4 4 3 4 6 8 5 4 7 1 5 3 1 4 8 5 6 6 5 4 2 6 4 2 8 6 4 2 3 8\n",
      "4444444444\n",
      "0.0\n",
      "0.106951871657754\n",
      "torch.Size([69, 1, 1000])\n",
      "torch.Size([15, 69, 9])\n",
      "torch.Size([1035, 9])\n",
      "18.435863494873047\n",
      "6 1 3 1 1 8 5 8 6 7 3 7 4 8 2 6 4 6 5 1 4 4 5 2 5 3 2 1 4 1 1 2 6 3 1 6 2 4 4 4 6 3 8 5 2 4 4 5 5 8 6 5 4 2 2 7 6 6 3 8 1 1 1 1 5 4 6 5 6 4 1 4 6 1 4 3 6 3 1 8 4 7 8 6 5 6 3 1 3 3 6 3\n",
      "4444444\n",
      "0.0\n",
      "0.0736842105263158\n",
      "torch.Size([51, 1, 1000])\n",
      "torch.Size([15, 51, 9])\n",
      "torch.Size([765, 9])\n",
      "26.930673599243164\n",
      "6 6 8 5 4 8 4 4 5 1 6 5 2 3 5 2 5 8 4 2 6 1 7 6 4 4 8 5 8 6 7 4 4 8 8 3 8 1 7 8 1 5 4 3 7 7 3 3 2\n",
      "4444444444\n",
      "0.0\n",
      "0.16822429906542058\n",
      "torch.Size([68, 1, 1000])\n",
      "torch.Size([15, 68, 9])\n",
      "torch.Size([1020, 9])\n",
      "18.871610641479492\n",
      "6 6 4 4 4 5 1 5 6 3 4 3 6 7 3 3 5 8 3 2 1 8 5 1 8 8 3 2 3 4 2 1 2 8 5 2 2 3 4 2 8 6 7 1 8 1 1 1 8 1 6 2 4 8 5 4 8 8 5 6 5 6 5 1 1 1 5 7 6 7 6 6 5 2 4 2 7 8 1 8 1 5 2 1 1 8 5 3 3\n",
      "4444444444444\n",
      "0.0\n",
      "0.09473684210526312\n",
      "torch.Size([61, 1, 1000])\n",
      "torch.Size([15, 61, 9])\n",
      "torch.Size([915, 9])\n",
      "21.95680809020996\n",
      "3 7 2 8 8 8 4 6 7 2 5 4 5 5 6 3 7 4 1 3 6 2 3 4 4 6 3 7 4 7 2 2 5 4 7 7 3 6 2 6 8 1 7 3 5 6 2 6 2 2 3 2 3 4 1 8 7 2 7 8 6 5 2 8 4 2 1 2 4 3\n",
      "444444444\n",
      "0.0\n",
      "0.1216216216216216\n",
      "torch.Size([65, 1, 1000])\n",
      "torch.Size([15, 65, 9])\n",
      "torch.Size([975, 9])\n",
      "19.439380645751953\n",
      "7 6 2 2 4 5 6 5 4 3 3 4 4 4 5 6 7 5 1 7 5 6 4 8 3 3 5 2 2 5 7 8 4 7 2 8 2 8 6 2 1 8 6 4 4 8 7 3 6 5 7 1 4 1 7 5 5 1 1 7 7 7 5 2 7 8 1 6 7 6 8 7 2 2 4 3 6 6 1 6 5 5 3\n",
      "444444444\n",
      "0.0\n",
      "0.10344827586206895\n",
      "torch.Size([52, 1, 1000])\n",
      "torch.Size([15, 52, 9])\n",
      "torch.Size([780, 9])\n",
      "26.27031135559082\n",
      "6 8 4 7 4 4 3 4 5 4 4 6 5 6 4 8 3 5 4 4 7 1 4 6 5 1 6 7 4 8 7 2 3 8 5 2 7 6 6 1 3 5 8 2 3 2 7 2 2 8 5\n",
      "44444\n",
      "0.0\n",
      "0.09433962264150941\n",
      "torch.Size([58, 1, 1000])\n",
      "torch.Size([15, 58, 9])\n",
      "torch.Size([870, 9])\n",
      "22.207778930664062\n",
      "6 5 6 4 7 6 5 1 7 4 5 7 5 8 2 1 3 1 3 1 7 1 6 7 8 8 2 1 5 5 2 2 3 5 4 1 3 2 8 4 4 4 1 1 4 3 5 8 8 1 4 7 4 8 4 1 1 5 5 7 6 3 7 8 7 7\n",
      "4444444444\n",
      "0.0\n",
      "0.14184397163120566\n",
      "torch.Size([59, 1, 1000])\n",
      "torch.Size([15, 59, 9])\n",
      "torch.Size([885, 9])\n",
      "22.596628189086914\n",
      "2 3 7 3 1 7 4 5 8 6 1 8 2 7 6 3 7 8 2 1 2 3 7 3 7 6 1 2 4 1 8 8 7 1 8 3 4 7 5 1 4 3 6 4 3 8 1 5 2 6 2 1 8 2 1 6 2 4 6 8 7 3 4 6 1 1\n",
      "4444444444\n",
      "0.0\n",
      "0.099290780141844\n",
      "torch.Size([67, 1, 1000])\n",
      "torch.Size([15, 67, 9])\n",
      "torch.Size([1005, 9])\n",
      "19.292095184326172\n",
      "1 1 5 6 3 5 2 8 2 5 1 1 4 5 7 2 1 8 8 4 6 1 8 2 1 2 8 6 8 5 1 4 8 5 1 2 7 2 3 4 3 4 1 2 5 4 7 4 3 1 4 6 6 5 7 2 3 3 1 7 7 2 6 7 2 2 5 5 4 4 1 1 8 7 1 1 4 5 3 2 1 3 7 5 5 4\n",
      "444444444444\n",
      "0.0\n",
      "0.1311475409836066\n",
      "torch.Size([50, 1, 1000])\n",
      "torch.Size([15, 50, 9])\n",
      "torch.Size([750, 9])\n",
      "30.576438903808594\n",
      "5 8 3 5 3 1 1 8 1 2 8 6 8 7 3 7 3 5 5 4 7 4 1 2 5 8 5 8 8 5 3 1 3 3 4 6 4 8 8 1 3 4 7\n",
      "44444444\n",
      "0.0\n",
      "0.10752688172043012\n",
      "torch.Size([72, 1, 1000])\n",
      "torch.Size([15, 72, 9])\n",
      "torch.Size([1080, 9])\n",
      "17.79323387145996\n",
      "6 7 7 7 6 4 4 1 4 3 6 6 8 5 6 8 5 6 1 2 6 6 7 1 2 1 5 4 5 7 1 6 8 8 3 4 3 6 3 5 7 3 8 6 7 5 2 4 3 1 3 7 4 5 7 6 5 6 2 1 7 8 4 1 8 7 2 1 8 4 2 3 5 4 8 5 2 4 8 3 8 4 5 3 6 5 8 4 2 6 2 8 2 8 2 5 7 8 4\n",
      "444444444444\n",
      "0.0\n",
      "0.11483253588516751\n",
      "torch.Size([62, 1, 1000])\n",
      "torch.Size([15, 62, 9])\n",
      "torch.Size([930, 9])\n",
      "19.780731201171875\n",
      "1 3 2 3 5 5 2 5 5 4 5 7 6 7 8 2 4 2 3 2 7 4 3 4 7 4 1 6 8 8 5 6 2 5 1 3 1 1 6 7 2 1 1 1 8 5 6 6 6 6 4 7 4 8 6 8 5 7 6 5 7 5 3 8 1 5 2 1 2 8 8 5 7 1 4 1 8 4\n",
      "444444\n",
      "0.0\n",
      "0.07453416149068326\n",
      "torch.Size([54, 1, 1000])\n",
      "torch.Size([15, 54, 9])\n",
      "torch.Size([810, 9])\n",
      "25.815126419067383\n",
      "2 6 3 5 2 8 5 8 1 7 1 1 5 6 2 8 8 1 5 7 6 7 8 6 8 1 3 1 1 3 3 1 7 6 1 8 6 3 1 7 1 4 1 8 5 8 4 5 5 5 3 3 6 3\n",
      "44444444444\n",
      "0.0\n",
      "0.03389830508474578\n",
      "torch.Size([71, 1, 1000])\n",
      "torch.Size([15, 71, 9])\n",
      "torch.Size([1065, 9])\n",
      "18.158817291259766\n",
      "4 2 5 3 7 2 7 4 6 7 7 2 6 5 5 8 7 7 4 3 3 3 5 1 8 3 5 3 8 8 4 6 8 3 2 7 5 6 1 7 5 4 4 2 1 6 5 8 4 7 8 6 1 8 1 4 4 5 7 3 1 3 2 1 4 6 1 3 5 4 1 3 2 8 4 7 8 2 4 6 1 7 7 3 3 3 3 4 1 6 4 1 5 5 6 3\n",
      "444444444\n",
      "0.0\n",
      "0.08999999999999997\n",
      "torch.Size([61, 1, 1000])\n",
      "torch.Size([15, 61, 9])\n",
      "torch.Size([915, 9])\n",
      "21.27393913269043\n",
      "2 4 2 2 5 8 1 6 8 7 7 6 5 6 6 6 3 6 4 6 5 3 7 1 4 4 8 8 2 2 6 8 2 8 2 3 5 8 3 3 8 1 1 8 3 6 5 1 4 2 7 5 6 1 7 4 4 5 6 7 4 4 4 2 6 1 1 6 6 5 7 6\n",
      "44444444\n",
      "0.0\n",
      "0.10596026490066224\n",
      "torch.Size([65, 1, 1000])\n",
      "torch.Size([15, 65, 9])\n",
      "torch.Size([975, 9])\n",
      "19.13193702697754\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#model_output_flattened = model_output.view(\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#    model_output.shape[0] * model_output.shape[1], n_classes)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m greedy_transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(greedy_decoder(model_output))\n\u001b[1;32m---> 36\u001b[0m beam_transcript \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_search_ctc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m actual_transcript \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m y])\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(actual_transcript)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\beam_search_decoder.py:60\u001b[0m, in \u001b[0;36mbeam_search_ctc\u001b[1;34m(prob_matrix, beam_width, blank, n_classes, return_alignments)\u001b[0m\n\u001b[0;32m     55\u001b[0m alignments, alignment_probs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, probs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(prob_matrix):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Get the top 3\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# previous_alignments adding - collapse at will - if the same as previous, don't add \u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# If new and the previous is blank, remove the blank\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     top_n \u001b[38;5;241m=\u001b[39m heapq\u001b[38;5;241m.\u001b[39mnlargest(beam_width, \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m)\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     61\u001b[0m     top_tokens \u001b[38;5;241m=\u001b[39m [i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_n]\n\u001b[0;32m     62\u001b[0m     top_probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(i[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_n]\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_tensor.py:1057\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[0;32m   1049\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[1;32m-> 1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "counter = 0\n",
    "sum_diff = 0\n",
    "gaps = 0\n",
    "identities = 0\n",
    "mismatches = 0\n",
    "\n",
    "for x, y in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
    "    \n",
    "    input_sequence = x.to(device)\n",
    "    target_sequence = torch.tensor(y).to(device)\n",
    "\n",
    "    #input_sequence = normalize([input_sequence], norm='l1')\n",
    "    print(input_sequence.shape)\n",
    "\n",
    "    model_output = model(input_sequence)\n",
    "    model_output = model_output.permute(1, 0, 2)  # Assuming log probs are computed in network\n",
    "    print(model_output.shape)\n",
    "    model_output = model_output.reshape(\n",
    "        model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "    print(model_output.shape)\n",
    "    \n",
    "\n",
    "    n_timesteps = model_output.shape[0]\n",
    "    input_lengths = torch.tensor([n_timesteps])\n",
    "    label_lengths = torch.tensor([len(target_sequence)])\n",
    "    \n",
    "  \n",
    "    loss = ctc(\n",
    "        log_probs=model_output, targets=target_sequence, input_lengths=input_lengths, target_lengths=label_lengths)\n",
    "    print(loss.item())\n",
    "    \n",
    "    #model_output_flattened = model_output.view(\n",
    "    #    model_output.shape[0] * model_output.shape[1], n_classes)\n",
    "    \n",
    "    greedy_transcript = \"\".join(greedy_decoder(model_output))\n",
    "    beam_transcript = beam_search_ctc(\n",
    "        model_output.detach().cpu(), beam_width=30)\n",
    "    \n",
    "\n",
    "    actual_transcript = \" \".join([str(i) for i in y])\n",
    "    print(actual_transcript)\n",
    "    print(greedy_transcript)\n",
    "    print(ratio(beam_transcript, actual_transcript))\n",
    "    print(ratio(greedy_transcript, actual_transcript))\n",
    "    \n",
    "    aligned = aligner.align(greedy_transcript, actual_transcript)[0].counts()\n",
    "\n",
    "    gaps += aligned[0] / len(actual_transcript)\n",
    "    identities += aligned[1] / len(actual_transcript)\n",
    "    mismatches += aligned[2] / len(actual_transcript)\n",
    "    #print(aligner.align(greedy_transcript, actual_transcript)[0].counts())\n",
    "\n",
    "print(gaps/64)\n",
    "print(identities/64)\n",
    "print(mismatches/64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\datasets\\synthetic\\working_datasets\\unnormalized\\synth_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
